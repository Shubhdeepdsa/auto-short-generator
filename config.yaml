project_name: "autos"
artifacts_dir: "artifacts"

logging:
  level: "INFO"

scene:
  # weâ€™ll use later
  min_scene_sec: 1.5

subtitles:
  # Subtitle timing offset in milliseconds (positive or negative).
  offset_ms: 0
  # Optional trim window for dev snippets.
  # For 10 min dev clips, override in .env:
  # SUBTITLE_TRIM_START_SEC=0
  # SUBTITLE_TRIM_END_SEC=600
  trim_start_sec: 0
  trim_end_sec: null

frames:
  # Default sample points (normalized positions inside a scene).
  sample_points: [0.25, 0.5, 0.75]
  # If a scene is shorter than this, extract only the midpoint.
  min_scene_sec: 1.0
  # Output image format: jpg or png.
  format: "jpg"
  # jpg: 2-31 (lower is higher quality); png: 0-9 (lower is higher quality).
  quality: 2

vision:
  # Caption model (image-to-text).
  caption_model: "Salesforce/blip-image-captioning-base"
  # Optional title model (text-to-text). Leave blank to use heuristic titles.
  title_model: ""
  # Device: auto, cpu, cuda, mps.
  device: "auto"
  # Caption/title batch size.
  batch_size: 4
  # Title max words (<= 8 recommended).
  title_max_words: 8
  # Title temperature (0 = deterministic).
  title_temperature: 0.0

scoring:
  # Ollama model name (must be pulled locally).
  model: "llama3.2:3b"
  # Prompt templates and schema.
  prompt_system_path: "prompts/score_system.txt"
  prompt_user_path: "prompts/score_user.txt"
  schema_path: "prompts/score_schema.json"
  # Deterministic defaults.
  temperature: 0.0
  top_p: 1.0
  top_k: 1
  seed: 0
  # Prompt size guards.
  max_dialogue_chars: 800
  max_caption_chars: 240
  max_title_chars: 80
  # Weights for total_score (computed in code).
  weights:
    hook: 1.0
    clarity: 1.0
    emotion: 1.0
    action: 1.0
    novelty: 1.0
    dialogue: 1.0
    visual: 1.0

chunking:
  # Prod defaults (30 min target, 2 min tolerance).
  # For dev snippets, override in .env:
  # CHUNK_TARGET_SEC=600  # 10 min
  # CHUNK_TOLERANCE_SEC=60
  target_sec: 1800
  tolerance_sec: 120
